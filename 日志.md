

[2021.3.31 Boost Tree&GBDT](#2021.3.29)

[2021.3.31 XGBoost](#2021.3.30)

[2021.3.31 FM&FFM](#2021.3.31)

[2021.3.31 FFM&DeepFM](#2021.4.1)


# 2021.3.29
 <span id="2021.3.29"></span>

- [x] 了解boost tree
  - [x] 提升树表现为决策树的加法模型。他构造T课树，除了第一颗树，每个树都在拟合上颗树造成的残差。
  - [x] $f_M(x)=\sum_{m=1}^MT_m(x)$
  - [x] 提升树选择依据：最小化平方误差
- [x] 了解GBDT
  - [x] GBDT是在提升树的基础上进行优化。每棵树不去拟合残差了，而是去拟合负梯度。

# 2021.3.30
 <span id="2021.3.30"></span>

- [x] 了解XGBoost 


# 2021.3.31
 <span id="2021.3.31"></span>
 
- [x] 了解了FM模型，概念以及数学推导。
  - [ ] FM：Feature Machine. 用于解决大规模稀疏数据的特征组合问题。
  - [ ] $FM:=w_0+\sum_{i=1}^n{w_ix_i}+\sum_{i=1}^n\sum_{j=i+1}^n{<v_i,v_j>x_i,x_j}$.
  - [ ] FM模型也直接引入任意两个特征的二阶特征组合，和SVM模型最大的不同，在于特征组合的权重的计算方法。
  - [ ] FM本质上是对特征进行embedding化表征，和目前非常常见的各种实体embedding 本质思想一致的。
  - [ ] 提出FM的意义？
- [ ] 初步了解FFM模型，数学推导还未了解。

# 2021.4.1
 <span id="2021.4.1"></span>

- [x] 理解FFM模型算法
  - [ ] 相比于FM模型，FFM引入了field的概念，特征可以被归类到field中。
  - [ ] $y(x)=w_0+\sum_{i=1}^d{w_ix_i}+\sum_{i+1}^d{\sum_{j=i+1}^d{(w_{i,f_j}\cdot w_{j,f_i})x_ix_j}}$
- [x] 理解DeepFM模型算法
  - [ ] DeepFM目的是同时学习低阶和高阶的特征交叉，主要由FM和DNN两部分组成，底部共享同样的输入。模型可以表示为 $\hat{y}=sigmoid(y_{FM}+y_{DNN})$